{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "mount_file_id": "1_TSg0C9kuO8UM2fjMD_MDCmS5D-ZhugM",
      "authorship_tag": "ABX9TyM/bSoNR0+CJ9FF0S3nOd+u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yagnesh25gehlot/Deep-Learning-Coursera/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El0y96yXoBul",
        "colab_type": "code",
        "outputId": "7de3660a-91f0-41a0-9f09-26b98f47e0a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a=2\n",
        "a\n",
        "print(a)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abflczVgdNsj",
        "colab_type": "code",
        "outputId": "f2e1e138-446d-4f8c-f9d3-68daacaf57fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "myfile = open(\"yg.txt\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e3ca389589a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yg.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'yg.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvJkcLTEeFYH",
        "colab_type": "code",
        "outputId": "bd43634d-fbc5-466f-e738-d3c3a605abc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "myfile = open(\"yg.txt\", 'a+')\n",
        "myfile.seek(0)\n",
        "print(myfile.read())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc5tT9GgfCOE",
        "colab_type": "code",
        "outputId": "157e2f7f-3cd5-4036-ce33-11a4b274bf18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "myfile.write(\"\\nThis is a new line\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMqyLonufJqr",
        "colab_type": "code",
        "outputId": "70ed4569-066d-4740-cda9-21fe5d0bce66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "myfile.seek(0)\n",
        "print(myfile.read())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c72dbee1da1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'myfile' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CTonvEcfUn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "mypdf = open('Lorem-Ipsum.pdf', mode='rb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9tRKEmEio7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdf_document = (mypdf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlAQlXeXjB-X",
        "colab_type": "code",
        "outputId": "f24c8d65-9d90-4af2-9f25-edfbf4bce0f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        " pip install PyPDF2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/01/68fcc0d43daf4c6bdbc6b33cc3f77bda531c86b174cac56ef0ffdb96faab/PyPDF2-1.26.0.tar.gz (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyPDF2\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-cp36-none-any.whl size=61086 sha256=19b52a3b369c13ed5726dba830d6381623a41769bececc4433d38c2ec2b1fd0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/84/19/35bc977c8bf5f0c23a8a011aa958acd4da4bbd7a229315c1b7\n",
            "Successfully built PyPDF2\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-1.26.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3dvdN93it7X",
        "colab_type": "code",
        "outputId": "433e772e-15dd-4e01-fa1f-31312e323912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "import PyPDF2\n",
        "mypdf = open('Lorem-Ipsum.pdf', mode='rb')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-71d28ffe23db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mPyPDF2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmypdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Lorem-Ipsum.pdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PyPDF2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97Lt8nG9ju1y",
        "colab_type": "code",
        "outputId": "82df3ece-ab3d-4843-df67-1629888e821f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "pdf_document = PyPDF2.PdfFileReader(mypdf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ee16256c3188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpdf_document\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyPDF2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPdfFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmypdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'PyPDF2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-WMVDIFj1a-",
        "colab_type": "code",
        "outputId": "d19f47aa-9991-41fc-faf9-c490d5d5b5f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pdf_document.numPages"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-9UBtAmj9uA",
        "colab_type": "code",
        "outputId": "f3c882de-3fb0-410b-a6ba-a185fc1be2a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "first_page = pdf_document.getPage(0)\n",
        "\n",
        "print(first_page.extractText())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lorem Ipsum\n",
            "is simply dummy text of the printing and typesetting \n",
            "industry. Lorem Ipsum has been the industry's standard dummy text ever \n",
            "since the 1500s, when an unknown printer took a galley of type and \n",
            "scrambled it to make a type specimen book. It has survived not only five \n",
            "centuries, but also the leap into electronic typesetting, remaining essentially \n",
            "unchanged. It was popularised in the 1960s with the release of Letraset \n",
            "sheets containing Lorem Ipsum passages, and more recently with desktop \n",
            "publishing software like Aldus PageMaker including versions of Lorem Ipsum.It is a long established fact that a reader will be distracted by the readable \n",
            "content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to \n",
            "using 'Content here, content here', making it look like readable English. \n",
            "Many desktop publishing packages and web page editors now use Lorem \n",
            "Ipsum as their default model text, and a search for 'lorem ipsum' will \n",
            "uncover many web sites still in their infancy. Various versions have evolved \n",
            "over the years, sometimes by accident, sometimes on purpose (injected \n",
            "humour and the like).Contrary to popular belief, Lorem Ipsum is not simply random text. It has \n",
            "roots in a pieceof classical Latin literature from 45 BC, making it over 2000 \n",
            "years old. Richard McClintock, a Latin professor at Hampden-Sydney College \n",
            "in Virginia, looked up one of the more obscure Latin words, consectetur, \n",
            "from a Lorem Ipsum passage, and going throughthe cites of the word in \n",
            "classical literature, discovered the undoubtable source. Lorem Ipsum comes \n",
            "from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" (The \n",
            "Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a \n",
            "treatise on the theory of ethics, very popular during the Renaissance. The \n",
            "first line of Lorem Ipsum, \"Lorem ipsum dolor sit amet..\", comes from a line \n",
            "in section 1.10.32.The standard chunk of Lorem Ipsum used since the 1500s is reproduced \n",
            "below for those interested. Sections 1.10.32 and 1.10.33 from \"de Finibus \n",
            "Bonorum et Malorum\" by Cicero are also reproduced in their exact original \n",
            "form, accompanied by English versions from the 1914 translation by H. \n",
            "Rackham.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DDmu6CunWOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdf_document_writer = PyPDF2.PdfFileWriter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHj7Nqb5n2_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import PyPDF2\n",
        "\n",
        "mypdf = open('Lorem-Ipsum.pdf', mode='rb')\n",
        "pdf_document = PyPDF2.PdfFileReader(mypdf)\n",
        "pdf_document.numPages\n",
        "\n",
        "page_one = pdf_document.getPage(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNXrkC4KoEph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdf_document_writer = PyPDF2.PdfFileWriter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz-8X8XjoTKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdf_document_writer.addPage(page_one)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv31XeMCoZWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdf_output_file = open('new_pdf_file.pdf', 'wb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI-ofVSIolXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdf_document_writer.write(pdf_output_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovpuji7dpb0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdf_output_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtvzXaIxpq8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mypdf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knqcmWMjpwLu",
        "colab_type": "code",
        "outputId": "d4d4a019-f31c-4b7e-88dc-143d6355d44b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "import PyPDF2\n",
        "\n",
        "mypdf = open(r'new_pdf_file.pdf', mode='rb')\n",
        "\n",
        "pdf_document = PyPDF2.PdfFileReader(mypdf)\n",
        "pdf_document.numPages\n",
        "page_one = pdf_document.getPage(0)\n",
        "\n",
        "print(page_one.extractText())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lorem Ipsum\n",
            "is simply dummy text of the printing and typesetting \n",
            "industry. Lorem Ipsum has been the industry's standard dummy text ever \n",
            "since the 1500s, when an unknown printer took a galley of type and \n",
            "scrambled it to make a type specimen book. It has survived not only five \n",
            "centuries, but also the leap into electronic typesetting, remaining essentially \n",
            "unchanged. It was popularised in the 1960s with the release of Letraset \n",
            "sheets containing Lorem Ipsum passages, and more recently with desktop \n",
            "publishing software like Aldus PageMaker including versions of Lorem Ipsum.It is a long established fact that a reader will be distracted by the readable \n",
            "content of a page when looking at its layout. The point of using Lorem Ipsum is that it has a more-or-less normal distribution of letters, as opposed to \n",
            "using 'Content here, content here', making it look like readable English. \n",
            "Many desktop publishing packages and web page editors now use Lorem \n",
            "Ipsum as their default model text, and a search for 'lorem ipsum' will \n",
            "uncover many web sites still in their infancy. Various versions have evolved \n",
            "over the years, sometimes by accident, sometimes on purpose (injected \n",
            "humour and the like).Contrary to popular belief, Lorem Ipsum is not simply random text. It has \n",
            "roots in a pieceof classical Latin literature from 45 BC, making it over 2000 \n",
            "years old. Richard McClintock, a Latin professor at Hampden-Sydney College \n",
            "in Virginia, looked up one of the more obscure Latin words, consectetur, \n",
            "from a Lorem Ipsum passage, and going throughthe cites of the word in \n",
            "classical literature, discovered the undoubtable source. Lorem Ipsum comes \n",
            "from sections 1.10.32 and 1.10.33 of \"de Finibus Bonorum et Malorum\" (The \n",
            "Extremes of Good and Evil) by Cicero, written in 45 BC. This book is a \n",
            "treatise on the theory of ethics, very popular during the Renaissance. The \n",
            "first line of Lorem Ipsum, \"Lorem ipsum dolor sit amet..\", comes from a line \n",
            "in section 1.10.32.The standard chunk of Lorem Ipsum used since the 1500s is reproduced \n",
            "below for those interested. Sections 1.10.32 and 1.10.33 from \"de Finibus \n",
            "Bonorum et Malorum\" by Cicero are also reproduced in their exact original \n",
            "form, accompanied by English versions from the 1914 translation by H. \n",
            "Rackham.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr7mHo4o50Bx",
        "colab_type": "code",
        "outputId": "3fa39a5c-b7b3-432c-be0c-1098be4917ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TqLeVGl6HGF",
        "colab_type": "code",
        "outputId": "739c4951-7ee2-44cc-c1c5-68aaa491025a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/5c/6439134ecd17b33fe0396fb0b7d6ce3c5a120c42a4516ba0e9a2d6e43b25/bert-for-tf2-0.14.4.tar.gz (40kB)\n",
            "\r\u001b[K     |████████                        | 10kB 15.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 1.8MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.4-cp36-none-any.whl size=30114 sha256=0ced236913052b961955a5e57f6be362a30fe17a005c8151acba9207b2309121\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/3f/4d/79d7735015a5f523648df90d871ce8e89a7df8185f7703eeab\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7302 sha256=c6563351c29e7ab4bf7f48dd0213d9e5f8d596f32e797c5b2df1afd6389409db\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19473 sha256=264e358375f67484a7e34fff084398d2b440dc50971d5b7608687e922d11c333\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.4 params-flow-0.8.2 py-params-0.9.7\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHAmy2_Z7V6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujngINbO72cS",
        "colab_type": "code",
        "outputId": "6ec793b8-460a-488f-f72e-5fefef2e0ca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "movie_reviews = pd.read_csv(r\"/content/drive/My Drive/IMDB_INTERNSHIP/train.csv\")\n",
        "\n",
        "movie_reviews.isnull().values.any()\n",
        "movie_reviews.sentiment= movie_reviews.sentiment.fillna(0.0).astype(int)#this will conver float into int and also manage missing values\n",
        "\n",
        "movie_reviews.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxzzJrpOA_qY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_text(sen):\n",
        "    # Removing html tags\n",
        "    sentence = remove_tags(sen)\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5M79UC3BOXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import re\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSu6iJpgFJFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N6xvqGrDnUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "reviews = []\n",
        "sentences = list(movie_reviews['text'])\n",
        "for sen in sentences:\n",
        "    reviews.append(preprocess_text(sen))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxEke7PoEImQ",
        "colab_type": "code",
        "outputId": "51e51eda-6a7c-497d-d4c0-191809dd8d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "print(movie_reviews.columns.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['text' 'sentiment']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EVTWuQ6FKq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y = movie_reviews['sentiment']\n",
        "\n",
        "y = np.array(list(map(lambda x: 1 if x==1 else 0, y)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbUiBSRbFjzG",
        "colab_type": "code",
        "outputId": "b8136033-3633-4eb3-be9a-f8e69f96acbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(reviews[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bizarre horror movie filled with famous faces but stolen by Cristina Raines later of TV Flamingo Road as pretty but somewhat unstable model with gummy smile who is slated to pay for her attempted suicides by guarding the Gateway to Hell The scenes with Raines modeling are very well captured the mood music is perfect Deborah Raffin is charming as Cristina pal but when Raines moves into creepy Brooklyn Heights brownstone inhabited by blind priest on the top floor things really start cooking The neighbors including fantastically wicked Burgess Meredith and kinky couple Sylvia Miles Beverly Angelo are diabolical lot and Eli Wallach is great fun as wily police detective The movie is nearly cross pollination of Rosemary Baby and The Exorcist but what combination Based on the best seller by Jeffrey Konvitz The Sentinel is entertainingly spooky full of shocks brought off well by director Michael Winner who mounts thoughtfully downbeat ending with skill from \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cpg8uRNF6K0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "\n",
        "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgBXZ53VGwHb",
        "colab_type": "code",
        "outputId": "df1ad4c2-e806-4812-f672-36724a7f205d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"don   what dis the fox ay \"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2123, 2054, 4487, 2015, 1996, 4419, 1037, 2100]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EafAUkahHSBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_reviews(text_reviews):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_reviews))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnxXSw8eHSXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_reviews = [tokenize_reviews(review) for review in reviews]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M-CWJ23HS31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_with_len = [[review, y[i], len(review)]\n",
        "                 for i, review in enumerate(tokenized_reviews)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAg42yf3HTFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.shuffle(reviews_with_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxB4fefnHTR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_with_len.sort(key=lambda x: x[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXeGHjXgHTXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_reviews_labels = [(review_lab[0], review_lab[1]) for review_lab in reviews_with_len]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqUxm4bfHTOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_reviews_labels, output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLMM71pTHTL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9sBbWzzHTJZ",
        "colab_type": "code",
        "outputId": "504aaefc-3847-4de2-991f-545e783f1048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "next(iter(batched_dataset))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 26), dtype=int32, numpy=\n",
              " array([[ 2023,  3185,  2003,  6659,  2021,  2009,  2038,  2070,  2204,\n",
              "          3896,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [ 1045,  2876,  9278,  2023,  2028,  2130,  2006,  7922, 12635,\n",
              "          2305,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [ 7918, 14674,  7662,  2003,  6581,  2003,  2023,  2143,  2002,\n",
              "          3084, 17160,  2450,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [11861,  1996, 21442,  6895,  3238,  2515,  2210, 22759,  6198,\n",
              "          1998,  3185,  2087, 12487,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [ 2017,  2488,  5454,  2703,  2310, 25032,  8913,  8159,  2130,\n",
              "          2065,  2017,  2031,  3427,  2009,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [ 2053,  7615,  5236,  3185,  3772,  2779,  2030,  4788,  9000,\n",
              "          2053,  3168,  2012,  2035, 13558,  2009,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [ 1045,  2123,  2113,  2339,  2066,  2023,  3185,  2061,  2092,\n",
              "          2021,  2196,  2131,  5458,  1997,  3666,  2009,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [ 2146, 11771,  1038,  8523,  8458,  6633,  3560,  2196,  2031,\n",
              "          2042,  2061,  5580,  2000,  2156,  4566,  6495,  4897,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [ 7615,  2023,  3185,  2003,  5263,  2003,  6659,  2200, 17727,\n",
              "          3217,  3676,  3468,  2919,  7613,  3257,  2025,  2298,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [ 2235,  3077,  2792,  3425,  2003,  1996,  2190,  2792,  1997,\n",
              "          2235,  3077,  2009,  2026,  5440,  2792,  1997,  2235,  3077,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [ 2023,  2003,  1996, 15764,  3185,  2544,  1997,  8429, 24905,\n",
              "         17988,  7659,  2498,  2021,  2045,  2024,  2053, 13842,  5312,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [ 2235,  3077,  2792,  3425,  2003,  1996,  2190,  2792,  1997,\n",
              "          2235,  3077,  2009,  2026,  5440,  2792,  1997,  2235,  3077,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [ 1037,  5790,  1997,  2515,  2025,  4088,  2000,  4671,  2129,\n",
              "         10634,  2139, 24128,  1998, 21660,  2135,  2919,  2023,  3185,\n",
              "          2003,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [ 7244,  2092,  2856, 10828,  1997, 10904,  2402,  2472,  3135,\n",
              "          2293,  2466,  2007, 10958,  8428, 10102,  1999,  1996,  4281,\n",
              "          4276,  3773,     0,     0,     0,     0,     0,     0],\n",
              "        [ 2307,  3185,  2926,  1996,  2189,  3802,  2696,  2508,  2012,\n",
              "          2197,  2023,  8847,  6702,  2043,  2017,  2031,  2633,  2179,\n",
              "          2008,  2569,  2619,     0,     0,     0,     0,     0],\n",
              "        [ 2023,  3185,  2097,  2467,  2022,  5934,  1998,  3185,  4438,\n",
              "          2004,  2146,  2004,  2045,  2024,  2145,  2111,  2040,  6170,\n",
              "          3153,  1998,  2552,     0,     0,     0,     0,     0],\n",
              "        [ 6581,  2792,  3185, 21862, 16016,  4349,  2420,  5920,  2015,\n",
              "          2009,  2987,  2102,  2131,  2062,  2139, 24128,  2084,  2023,\n",
              "          3185,  5790,  2189,  5790,     0,     0,     0,     0],\n",
              "        [ 2065,  2017,  4033,  2464,  2023,  2009,  6659,  2009,  2003,\n",
              "          5760, 11669,  2387,  2023,  2055,  2086,  3283,  1998,  1049,\n",
              "          2145, 14180,  2039,  2013,  2009,     0,     0,     0],\n",
              "        [ 2004,  5156,  5977, 17639,  2100,  2515,  2307,  3105,  5623,\n",
              "          3869,  8022,  2003,  2204,  2021,  2031,  2524,  2051,  2025,\n",
              "          3773,  2032,  2004, 25209,  6769,     0,     0,     0],\n",
              "        [ 4895, 18866,  3085,  2017,  2064,  2130,  2191,  2009,  2627,\n",
              "          1996,  2034,  2093,  2781,  1998,  2023,  2003,  2746,  2013,\n",
              "          4121,  4205,  5472,  3917,  5470,     0,     0,     0],\n",
              "        [ 8235,  3185,  1996,  9254,  2020,  2074,  6429,  2205,  2919,\n",
              "          2009,  3092,  2077,  2009,  5625,  2310,  4741,  2086,  2005,\n",
              "          8297,  2021,  2053,  9541,  9541,     0,     0,     0],\n",
              "        [ 5525,  2517,  2005,  1996,  2754, 12038,  2021,  4276, 19927,\n",
              "          2129,  2064,  2017,  2175,  3308,  2007,  6798,  9482, 14439,\n",
              "          1998, 21442,  2571, 15578,  4948,     0,     0,     0],\n",
              "        [ 1996,  3494,  2024,  4406,  3085,  1998,  1996,  5896,  2003,\n",
              "          9643,  2009,  1037,  5949,  1997,  1996, 11725,  1997,  7939,\n",
              "         13765,  3726,  1998,  8740,  2618, 19231,     0,     0],\n",
              "        [ 2023,  2003,  2302,  4797,  1996,  5409,  3185,  2031,  2412,\n",
              "          2464,  2009,  2003,  2025,  6057,  2009,  2003,  2025,  5875,\n",
              "          1998,  2323,  2025,  2031,  2042,  2081,     0,     0],\n",
              "        [ 1996,  2069,  9487,  2755,  2003,  1996,  6577,  1997, 16536,\n",
              "         12631,  5488,  2040,  3248,  5011,  2123,  3198,  2033,  2339,\n",
              "          2002,  2515,  2009,  2919,  2919,  3185,  3452,     0],\n",
              "        [ 2020,  2025,  2007,  2814,  1998,  2061, 10036,  2052,  2031,\n",
              "          2939,  2041,  2009,  3478, 28616,  6906,  6321,  2004, 18312,\n",
              "          1998,  2134,  2130,  2031,  1996, 18434,  1997,  3409],\n",
              "        [ 2919,  3185,  2009,  2205,  8552,  2005,  2402,  2336,  1998,\n",
              "          2205, 24282,  2005,  4961, 11139,  2074,  2387,  2009,  2138,\n",
              "          1049,  5863,  3766,  5470,  1998,  2001,  2200,  9364],\n",
              "        [ 8861, 25005,  2038,  2025,  2018,  2205,  2116,  2204,  5691,\n",
              "          9906,  1998,  2023,  2003,  2053,  2367,  2926,  2881,  2005,\n",
              "          2111,  2040,  2066,  3756, 17736,  2006,  2037,  5691],\n",
              "        [ 2023,  2143,  2081,  2198, 20012,  2732,  5070, 15547,  8029,\n",
              "          2003,  2028,  1997,  1996,  2087, 17075,  2839,  2008,  2031,\n",
              "          2412,  2464,  2006,  2143,  1998,  2812,  2008,  4368],\n",
              "        [ 2921,  2026,  3086,  2013,  2707,  2000,  3926,  2307,  4616,\n",
              "          2794,  2000,  2023, 14388,  2143,  2720, 14397,  5740,  2320,\n",
              "          2153,  3957,  2149,  2178,  8235,  2839,  2000,  5959],\n",
              "        [ 2302,  3160,  1996,  5409, 12280,  2143,  2412,  2081,  1996,\n",
              "          3185, 17509,  2035,  6505,  2004,  7144,  5236,  1998, 13971,\n",
              "          3422, 12280,  3096,  2689,  3609,  2802,  1996,  2143],\n",
              "        [ 1045,  2228,  2009,  2028,  1997,  1996,  4602,  5691,  2029,\n",
              "          2024,  2412,  2081,  1998,  2310,  2464,  2116,  1996,  2338,\n",
              "          2003,  2488,  2021,  2009,  2145,  2200,  2204,  3185]],\n",
              "       dtype=int32)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 1, 0, 0, 1, 0], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gk1xOlyHTBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "TOTAL_BATCHES = math.ceil(len(sorted_reviews_labels) / BATCH_SIZE)\n",
        "TEST_BATCHES = TOTAL_BATCHES // 10\n",
        "batched_dataset.shuffle(TOTAL_BATCHES)\n",
        "test_data = batched_dataset.take(TEST_BATCHES)\n",
        "train_data = batched_dataset.skip(TEST_BATCHES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCV_-9iOHS_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TEXT_MODEL(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocabulary_size,\n",
        "                 embedding_dimensions=128,\n",
        "                 cnn_filters=50,\n",
        "                 dnn_units=600,\n",
        "                 model_output_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name=\"text_model\"):\n",
        "        super(TEXT_MODEL, self).__init__(name=name)\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocabulary_size,\n",
        "                                          embedding_dimensions)\n",
        "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=2,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=3,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=4,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if model_output_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=model_output_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        l = self.embedding(inputs)\n",
        "        l_1 = self.cnn_layer1(l) \n",
        "        l_1 = self.pool(l_1) \n",
        "        l_2 = self.cnn_layer2(l) \n",
        "        l_2 = self.pool(l_2)\n",
        "        l_3 = self.cnn_layer3(l)\n",
        "        l_3 = self.pool(l_3) \n",
        "        \n",
        "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) # (batch_size, 3 * cnn_filters)\n",
        "        concatenated = self.dense_1(concatenated)\n",
        "        concatenated = self.dropout(concatenated, training)\n",
        "        model_output = self.last_dense(concatenated)\n",
        "        \n",
        "        return model_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG0QOaClHS8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "VOCAB_LENGTH = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "CNN_FILTERS = 100\n",
        "DNN_UNITS = 256\n",
        "OUTPUT_CLASSES = 2\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "NB_EPOCHS = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gohU1C7YHS0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
        "                        embedding_dimensions=EMB_DIM,\n",
        "                        cnn_filters=CNN_FILTERS,\n",
        "                        dnn_units=DNN_UNITS,\n",
        "                        model_output_classes=OUTPUT_CLASSES,\n",
        "                        dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtXLCM-_HSxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if OUTPUT_CLASSES == 2:\n",
        "    text_model.compile(loss=\"binary_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"accuracy\"])\n",
        "else:\n",
        "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOn_LBSCHSvP",
        "colab_type": "code",
        "outputId": "898b522e-de8b-481c-bdb7-f85a2d9f6c8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "text_model.fit(train_data, epochs=NB_EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "704/704 [==============================] - 227s 323ms/step - loss: 0.3512 - accuracy: 0.8359\n",
            "Epoch 2/2\n",
            "704/704 [==============================] - 222s 315ms/step - loss: 0.1391 - accuracy: 0.9481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fef325ad518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skTJr69THSrb",
        "colab_type": "code",
        "outputId": "03174fde-13d9-485d-af7c-4bfabde2561d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "results = text_model.evaluate(test_data)\n",
        "print(results)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78/78 [==============================] - 2s 24ms/step - loss: 0.3072 - accuracy: 0.8946\n",
            "[0.3072136342525482, 0.8946313858032227]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5ewCdF3HSoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Stage 5: Evaluation\n",
        "\n",
        "def get_prediction(sentence):\n",
        "    tokens = tokenize_reviews(sentence)\n",
        "    inputs = tf.expand_dims(tokens, 0)\n",
        "\n",
        "    output = text_model(inputs, training=False)\n",
        "    output=output.isnull()\n",
        "    #output.sentiment= output.sentiment.fillna(0.0).astype(int) \n",
        "\n",
        "    sentiment = math.floor(output*2)\n",
        "    \n",
        "#     df = df[~df['x'].isnull()]\n",
        "\n",
        "# # Y contained some other garbage, so null check was not enough\n",
        "# df = df[df['y'].str.isnumeric()]\n",
        "\n",
        "# # final conversion now worked\n",
        "# df[['x']] = df[['x']].astype(int)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    if sentiment == 0:\n",
        "        print(\"Ouput of the model: {}\\nPredicted sentiment: negative.\".format(\n",
        "            output))\n",
        "    elif sentiment == 1:\n",
        "        print(\"Ouput of the model: {}\\nPredicted sentiment: positive.\".format(\n",
        "            output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKgefFtZHSVz",
        "colab_type": "code",
        "outputId": "79db40f2-b31e-43ea-ff24-07c386f87ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "\n",
        "get_prediction(\"best movie ever\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-76445b6d60c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best movie ever\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-61-680b55c3912c>\u001b[0m in \u001b[0;36mget_prediction\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#output.sentiment= output.sentiment.fillna(0.0).astype(int)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'isnull'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y4NqP1cHSTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow_GyfYoux96",
        "colab_type": "text"
      },
      "source": [
        "break\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqQt7RsFHSQl",
        "colab_type": "code",
        "outputId": "043bea62-b778-46af-de3f-baa095228ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jv8-jsUHSNm",
        "colab_type": "code",
        "outputId": "01e6611a-9f28-4f0f-9fdd-86a543b633a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "!pip install tensorflow==1.15\n",
        "!pip install \"tensorflow_hub>=0.6.0\"\n",
        "!pip3 install tensorflow_text==1.15\n",
        "#requirements"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 18kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.29.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 47.4MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.2.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (47.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=3e3c35393385f28020efa240651b6d03279fa7680c268ff0df795a4b939f632a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, gast, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Requirement already satisfied: tensorflow_hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (1.18.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow_hub>=0.6.0) (47.1.1)\n",
            "Collecting tensorflow_text==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/61/9569353ce3efb8ee818d0d2e2f67afbb19e1e3a56eba3a93986e92949003/tensorflow_text-1.15.0-cp36-cp36m-manylinux1_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<1.16,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.2.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.29.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.34.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.18.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.8.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.12.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.8)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (47.1.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.1.0)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvjrTj59vuw_",
        "colab_type": "code",
        "outputId": "2b04b769-5159-4991-a4ff-80e7c0efdf36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# load packages\n",
        "from sklearn import metrics,preprocessing,model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "import keras\n",
        "from keras.layers import Input, Lambda, Dense\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import string\n",
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "spacy.load('en')\n",
        "parser = English()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEqNOmyHvuuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get elmo from tensorflow hub\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvQNHyW5vurG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP_UjaMNvuow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# ELMo Embedding\n",
        "def ELMoEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4UNHNoHvul6",
        "colab_type": "code",
        "outputId": "350c7380-7ec0-4154-879e-17868d3f2da0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b357X-YvujL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "a285ca7f-46e0-4b7a-937d-74a954af3884"
      },
      "source": [
        "\n",
        "# Stop words and special characters \n",
        "STOPLIST = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS)) \n",
        "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-\", \"...\", \"”\", \"”\",\"''\"]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c56a3a40af19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Stop words and special characters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mSTOPLIST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mENGLISH_STOP_WORDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mSYMBOLS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"”\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"”\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"''\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stopwords' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X0SeDEsvugE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizeText(text):\n",
        "    \n",
        "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
        "    text = text.lower()\n",
        "    \n",
        "    tokens = parser(text)\n",
        "    \n",
        "    # lemmatization\n",
        "    lemmas = []\n",
        "    for tok in tokens:\n",
        "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
        "    tokens = lemmas\n",
        "    \n",
        "    # reomve stop words and special charaters\n",
        "    tokens = [tok for tok in tokens if tok.lower() not in STOPLIST]\n",
        "    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n",
        "    \n",
        "    tokens = [tok for tok in tokens if len(tok) >= 3]\n",
        "    \n",
        "    # remove remaining tokens that are not alphabetic\n",
        "    tokens = [tok for tok in tokens if tok.isalpha()]\n",
        "    \n",
        "    tokens = list(set(tokens))\n",
        "    \n",
        "    return ' '.join(tokens[:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xWZS_IavudX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#one -hot encoding\n",
        "def encode(le_enc, labels):\n",
        "    enc = le_enc.transform(labels)\n",
        "    return keras.utils.to_categorical(enc)\n",
        "\n",
        "def decode(le_enc, one_hot):\n",
        "    dec = np.argmax(one_hot, axis=1)\n",
        "    return le_enc.inverse_transform(dec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StlM2JWcvuZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the dataset\n",
        "trainDF_Sheet_1 = pd.read_csv(r\"/content/drive/My Drive/IMDB_INTERNSHIP/train.csv\",encoding='latin-1')\n",
        "trainDF_Sheet_1.isnull().values.any()\n",
        "trainDF_Sheet_1.sentiment= trainDF_Sheet_1.sentiment.fillna(0.0).astype(int)#this will conver float into int and also manage missing values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu4sEQApvuUX",
        "colab_type": "code",
        "outputId": "0ccc4247-8d71-49e2-a6ea-1763469c671b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "trainDF_Sheet_1.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>For a movie that gets no respect there sure ar...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bizarre horror movie filled with famous faces ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A solid, if unremarkable film. Matthau, as Ein...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It's a strange feeling to sit alone in a theat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You probably all already know this by now, but...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I saw the movie with two grown children. Altho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>You're using the IMDb.  You've given some heft...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This was a good film with a powerful message o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Made after QUARTET was, TRIO continued the qua...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>For a mature man, to admit that he shed a tear...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment\n",
              "0  For a movie that gets no respect there sure ar...          0\n",
              "1  Bizarre horror movie filled with famous faces ...          0\n",
              "2  A solid, if unremarkable film. Matthau, as Ein...          0\n",
              "3  It's a strange feeling to sit alone in a theat...          0\n",
              "4  You probably all already know this by now, but...          0\n",
              "5  I saw the movie with two grown children. Altho...          0\n",
              "6  You're using the IMDb.  You've given some heft...          0\n",
              "7  This was a good film with a powerful message o...          0\n",
              "8  Made after QUARTET was, TRIO continued the qua...          0\n",
              "9  For a mature man, to admit that he shed a tear...          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GY23hlmvuRD",
        "colab_type": "code",
        "outputId": "f7fafd46-b598-4913-95ab-626966cd8d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainDF_Sheet_1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-NC6vwxwvq-",
        "colab_type": "code",
        "outputId": "478e356c-c795-4aa2-ebc1-088208400861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainDF_Sheet_1['sentiment'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqkcROGtwvoD",
        "colab_type": "code",
        "outputId": "3bba71d5-eb58-4200-c7ad-f5ffb9749969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "trainDF_Sheet_1['sentiment'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12500\n",
              "0    12500\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3Qlg-T9wvk8",
        "colab_type": "code",
        "outputId": "19c5a9be-2dad-402a-8e6e-7e0aa1338a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        }
      },
      "source": [
        "sns.set(rc={'figure.figsize':(8,8)})\n",
        "sns.countplot(trainDF_Sheet_1['sentiment'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb43ef57b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj2RBvXLwveb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Data cleaning\n",
        "trainDF_Sheet_1['response_text'] = trainDF_Sheet_1['text'].apply(lambda x:tokenizeText(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDauljF8wvaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Data preparation\n",
        "X = trainDF_Sheet_1['response_text'].tolist()\n",
        "y = trainDF_Sheet_1['sentiment'].tolist()\n",
        "\n",
        "# Lebel encoding\n",
        "le_enc = preprocessing.LabelEncoder()\n",
        "le_enc.fit(y)\n",
        "\n",
        "y_en = encode(le_enc, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJV9StTowvTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# split the dataset into training and testing datasets\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(np.asarray(X), np.asarray(y_en), test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5n2BWjUvuMB",
        "colab_type": "code",
        "outputId": "3346067b-2d87-4682-8297-4103311e41e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3cuqHKD-jWT",
        "colab_type": "code",
        "outputId": "aef0545d-d7f2-4fc2-e822-17158a127c31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        " \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJEh63ft_4R6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzljjcL8AJvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "from os import listdir\n",
        "from nltk.corpus import stopwords\n",
        "from pickle import dump"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2N_lFttAXJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "\n",
        "from pickle import load\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "\n",
        "from pickle import load\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.merge import concatenate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V7fTI3LvuF8",
        "colab_type": "code",
        "outputId": "6055b487-4b91-41ff-9cbf-f48a728f2602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from pickle import load\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.merge import concatenate\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Build Model\n",
        "input_text = Input(shape=(1,), dtype=tf.string)\n",
        "embedding1 = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
        "embedding2 = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
        "embedding3 = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
        "dense1 = Dense(256, activation='relu')(embedding1)\n",
        "dense2 = Dense(256, activation='relu')(embedding2)\n",
        "dense3 = Dense(256, activation='relu')(embedding3)\n",
        "# flat1 = Flatten()(dense1)\n",
        "# flat2 = Flatten()(dense2)\n",
        "# flat3 = Flatten()(dense3)\n",
        "# merge\n",
        "merged = concatenate([dense1, dense2, dense3])\n",
        "dense4 = Dense(10, activation='relu')(merged)\n",
        "pred = Dense(2, activation='softmax')(dense4)\n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())  \n",
        "    session.run(tf.tables_initializer())\n",
        "    history = model.fit(x_train, y_train, epochs=3, batch_size=16)\n",
        "    model.save_weights('./response-elmo-model.h5')\n",
        "\n",
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    session.run(tf.tables_initializer())\n",
        "    model.load_weights('./response-elmo-model.h5')  \n",
        "    predicts = model.predict(x_test, batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20000/20000 [==============================] - 1823s 91ms/step - loss: 0.6936 - accuracy: 0.4983\n",
            "Epoch 2/3\n",
            "11408/20000 [================>.............] - ETA: 13:07 - loss: 0.6932 - accuracy: 0.4947"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU9YNn4SHSJv",
        "colab_type": "code",
        "outputId": "523819bf-f77d-41ad-ed68-a7af5fa77098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "\n",
        "# Build Model\n",
        "input_text = Input(shape=(1,), dtype=tf.string)\n",
        "embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
        "dense = Dense(256, activation='relu')(embedding)\n",
        "pred = Dense(2, activation='softmax')(dense)\n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())  \n",
        "    session.run(tf.tables_initializer())\n",
        "    history = model.fit(x_train, y_train, epochs=3, batch_size=16)\n",
        "    model.save_weights('./response-elmo-model.h5')\n",
        "\n",
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    session.run(tf.tables_initializer())\n",
        "    model.load_weights('./response-elmo-model.h5')  \n",
        "    predicts = model.predict(x_test, batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "20000/20000 [==============================] - 688s 34ms/step - loss: 0.4919 - accuracy: 0.7621\n",
            "Epoch 2/3\n",
            "20000/20000 [==============================] - 651s 33ms/step - loss: 0.4330 - accuracy: 0.7988\n",
            "Epoch 3/3\n",
            "20000/20000 [==============================] - 644s 32ms/step - loss: 0.4211 - accuracy: 0.8060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FsmuWAyx3L2",
        "colab_type": "code",
        "outputId": "30ad7f71-1722-4eac-8ba9-43bed7d0ba8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "# decode test labels\n",
        "y_test = decode(le_enc, y_test)\n",
        "# decode predicted labels\n",
        "y_preds = decode(le_enc, predicts) "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f656dcb225b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# decode test labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# decode predicted labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'decode' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB52SX82x3GI",
        "colab_type": "code",
        "outputId": "3b814d48-4821-41ad-db47-a3a0acc132c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(metrics.confusion_matrix(y_test, y_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1794  721]\n",
            " [ 277 2208]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgOsTA-m5_m4",
        "colab_type": "code",
        "outputId": "c23e3372-cf94-49b4-81d9-b7b93755443a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(metrics.classification_report(y_test, y_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.71      0.78      2515\n",
            "           1       0.75      0.89      0.82      2485\n",
            "\n",
            "    accuracy                           0.80      5000\n",
            "   macro avg       0.81      0.80      0.80      5000\n",
            "weighted avg       0.81      0.80      0.80      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYt01tow5_i9",
        "colab_type": "code",
        "outputId": "3a39dd8d-bfd1-4460-cc5f-a5de497f9f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Accuracy of ELMO is:\",accuracy_score(y_test,y_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of ELMO is: 0.8004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6h1hSzM5_dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klaNJbXkxOj4",
        "colab_type": "text"
      },
      "source": [
        "break\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvZnbmdg5_WZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6nPIEKFx2_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
